{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDgRrdjhhFUB"
   },
   "source": [
    "## Step 1. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXTFbrVHhFUE"
   },
   "outputs": [],
   "source": [
    "# import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, multilabel_confusion_matrix\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, GroupKFold, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, OneHotEncoder, RobustScaler, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mPPkojMhFUF"
   },
   "source": [
    "## Step 2a. Declare user variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T3-fnNiUhFUG"
   },
   "outputs": [],
   "source": [
    "is_test = False\n",
    "is_dataset_one_file = False\n",
    "\n",
    "user_specified_layout = 'layout1'\n",
    "user_specified_layout_int = int(user_specified_layout[len(user_specified_layout) - 1])\n",
    "user_specified_clf = 'all'\n",
    "\n",
    "user_test_size = 0.2\n",
    "user_random_state = 1\n",
    "\n",
    "if user_specified_layout_int == 1:\n",
    "    ith_inp_col = 16\n",
    "else:\n",
    "    ith_inp_col = 20\n",
    "\n",
    "list_filenames = {\n",
    "    'layout1':'dataset1.csv',\n",
    "    'layout2':'dataset2.csv',\n",
    "}\n",
    "list_columns = {\n",
    "    'layout1_all':['timestamp','posture_id','posture_label','s01','s02','s03','s04','s05','s06','s07','s08','s09','s10','s11','s12','s13','s14','s15','s16','birth_year','sex','height','weight','bmi','bmi_label','full_name','nth','round'],\n",
    "    'layout2_all':['timestamp','posture_id','posture_label','s01','s02','s03','s04','s05','s06','s07','s08','s09','s10','s11','s12','s13','s14','s15','s16','s17','s18','s19','s20','birth_year','sex','height','weight','bmi','bmi_label','full_name','nth','round'],\n",
    "    'layout1_cat_inp':[],\n",
    "    'layout1_num_inp':['s01','s02','s03','s04','s05','s06','s07','s08','s09','s10','s11','s12','s13','s14','s15','s16', 'height','weight','bmi'],\n",
    "    'layout2_cat_inp':[],\n",
    "    'layout2_num_inp':['s01','s02','s03','s04','s05','s06','s07','s08','s09','s10','s11','s12','s13','s14','s15','s16','s17','s18','s19','s20', 'height','weight','bmi'],\n",
    "}\n",
    "list_positions = ['Yearner_Right', 'Yearner_Left', 'Fetal_Right', 'Fetal_Left', 'Log_Right', 'Log_Left', 'Supine', 'Prone',\n",
    "                  # 'Empty'\n",
    "]\n",
    "list_grouped_positions = [\n",
    "    'Rights',\n",
    "    'Lefts',\n",
    "#     'Fetal_Right',\n",
    "#     'Fetal_Left',\n",
    "    'Supine',\n",
    "    'Prone',\n",
    "]\n",
    "\n",
    "# {\n",
    "#     'Yearner_Right' : 1,\n",
    "#     'Yearner_Left' : 2,\n",
    "#     'Fetal_Right' : 3,\n",
    "#     'Fetal_Left' : 4,\n",
    "#     'Log_Right' : 5,\n",
    "#     'Log_Left' : 6,\n",
    "#     'Supine' : 7,\n",
    "#     'Prone' : 8,\n",
    "# }\n",
    "\n",
    "filename = list_filenames[user_specified_layout]\n",
    "cols_all = list_columns[user_specified_layout + '_all']\n",
    "cols_cat_inp = list_columns[user_specified_layout + '_cat_inp']\n",
    "cols_num_inp = list_columns[user_specified_layout + '_num_inp']\n",
    "cols_inp = cols_cat_inp + cols_num_inp\n",
    "cols_drp = list(set(cols_all) - set(cols_inp))\n",
    "\n",
    "cols_num_inp_std = ['height','weight','bmi']\n",
    "cols_num_inp_nrm = list(set(cols_num_inp) - set(cols_num_inp_std))\n",
    "\n",
    "col_grp = 'full_name'\n",
    "col_trg = 'posture_id'\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "sns.reset_orig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIpQ_xVEhFUH"
   },
   "source": [
    "## Step 2b. Declare and prepare needed variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if is_dataset_one_file:\n",
    "    df = pd.read_csv(filename, usecols = cols_all)\n",
    "else:\n",
    "    import os\n",
    "    import glob\n",
    "\n",
    "    # os.chdir(\"C:/Users/Julianne/Documents/Notebooks/thesis/data/set_{}\".format(user_specified_layout_int))\n",
    "    os.chdir(\"C:/Users/Julianne/Downloads/set_{} clean\".format(user_specified_layout_int))\n",
    "\n",
    "    extension = 'csv'\n",
    "    list_raw_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "\n",
    "    df = pd.concat([pd.read_csv(f, usecols = cols_all) for f in list_raw_filenames])\n",
    "\n",
    "    df = df[df.nth <= 5]\n",
    "    df = df[df.nth == 3]\n",
    "\n",
    "    ## export to csv\n",
    "    # combined_csv.to_csv(\"dataset{}.csv\".format(user_specified_layout_int), index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    os.chdir(\"C:/Users/Julianne/Documents/Notebooks/thesis\".format(user_specified_layout_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_test:\n",
    "    df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if is_test:\n",
    "    df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "n2Tq6jamhFUI",
    "outputId": "03ff5da5-6b56-4553-b782-7b0d8d54a977"
   },
   "outputs": [],
   "source": [
    "def categorize(row):\n",
    "    if row['posture_label'] == 'Yearner_Right' or row['posture_label'] == 'Log_Right' or row['posture_label'] == 'Fetal_Right':\n",
    "        return 100\n",
    "    elif row['posture_label'] == 'Yearner_Left' or row['posture_label'] == 'Log_Left' or row['posture_label'] == 'Fetal_Left':\n",
    "        return 200\n",
    "    else:\n",
    "        return row['posture_id']\n",
    "\n",
    "df_inp = df.drop(columns=cols_drp)\n",
    "\n",
    "X = df_inp\n",
    "\n",
    "y = df[col_trg].values\n",
    "y_intermediate = df.apply(lambda row: categorize(row), axis=1).values\n",
    "groups = df[col_grp].values\n",
    "\n",
    "# TODO: delete cols_identifying_idx and other calls to this variable\n",
    "cols_identifying_idx = df_inp.columns.get_indexer(['height','weight','bmi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cat_inp_idx = df_inp.columns.get_indexer(cols_cat_inp)\n",
    "cols_num_inp_idx = df_inp.columns.get_indexer(cols_num_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #apply SelectKBest class to extract top 10 best features\n",
    "# bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "# fit = bestfeatures.fit(X,y)\n",
    "# dfscores = pd.DataFrame(fit.scores_)\n",
    "# dfcolumns = pd.DataFrame(X.columns)\n",
    "# #concat two dataframes for better visualization \n",
    "# featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "# featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "# print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ioH2V3TchFUI"
   },
   "source": [
    "## Step 3. Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eI9WFkYJhFUJ"
   },
   "outputs": [],
   "source": [
    "if is_test:\n",
    "    df_inp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GMkVIaQRhFUK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.plotting.scatter_matrix(X, figsize=(10, 10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LF9YPeeyhFUL"
   },
   "outputs": [],
   "source": [
    "if is_test:\n",
    "    # Create correlation matrix\n",
    "    corr_matrix = df.drop(columns=cols_drp).corr()\n",
    "\n",
    "    # Define mask used to cover squares above diagonal\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "    plt.figure(figsize=(20, 10), facecolor='w', edgecolor='k')\n",
    "    plt.title('Correlation Matrix - ' + user_specified_layout)\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(corr_matrix, cmap='coolwarm', center = 0, annot=True, fmt='.1g', mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_cat_inp = [\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "]\n",
    "pipe_cat_inp = Pipeline(steps_cat_inp)\n",
    "\n",
    "steps_num_inp = [\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "]\n",
    "pipe_num_inp = Pipeline(steps_num_inp)\n",
    "\n",
    "ct = ColumnTransformer(transformers=[\n",
    "          ('categorical', pipe_cat_inp, cols_cat_inp_idx),\n",
    "          ('numerical', pipe_num_inp, cols_num_inp_idx)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[col_grp].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBFxrSSahFUM"
   },
   "source": [
    "## Step 4. Declare needed functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(actual_targets, predicted_targets, target_classes):\n",
    "    print(accuracy_score(actual_targets, predicted_targets))\n",
    "#     print(precision_score(actual_targets, predicted_targets, average='micro'))\n",
    "#     print(recall_score(actual_targets, predicted_targets, average='micro'))\n",
    "#     print(f1_score(actual_targets, predicted_targets, average='micro'))\n",
    "#     try:\n",
    "#         print(classification_report(actual_targets, predicted_targets, target_names=target_classes))\n",
    "#     except:\n",
    "#         print(classification_report(actual_targets, predicted_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_confusion_matrix(cnf_matrix, actual_targets, predicted_targets, target_classes, normalize=False, title='Confusion Matrix'):\n",
    "    if normalize:\n",
    "        cnf_matrix = cnf_matrix.astype('float') / cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Confusion Matrix, With Normalized Counts\")\n",
    "        ConfusionMatrixDisplay.from_predictions(actual_targets, predicted_targets,\n",
    "                                                xticks_rotation = 45, \n",
    "                                                normalize='true', \n",
    "                                                values_format = '.2f')\n",
    "    else:\n",
    "        print(\"Confusion Matrix, Without Normalized Counts\")\n",
    "        ConfusionMatrixDisplay.from_predictions(actual_targets, predicted_targets,\n",
    "                                                xticks_rotation = 45)\n",
    "\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    return cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(actual_targets, predicted_targets, classifier, target_classes):\n",
    "    cm = confusion_matrix(actual_targets, predicted_targets)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    print_metrics(actual_targets, predicted_targets, target_classes)\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    plt.figure()\n",
    "    generate_confusion_matrix(cm, actual_targets, predicted_targets, target_classes=target_classes, title='%s Confusion Matrix - Layout %x (Without Normalized Counts)' % (classifier, user_specified_layout_int))\n",
    "    plt.savefig('CM-L%x-%s-all-nonnormalized.svg' % (user_specified_layout_int, classifier), format='svg', bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot normalized confusion matrix\n",
    "    plt.figure()\n",
    "    generate_confusion_matrix(cm, actual_targets, predicted_targets, target_classes=target_classes, normalize=True, title='%s Confusion Matrix - Layout %x (With Normalized Counts)' % (classifier, user_specified_layout_int))\n",
    "    plt.savefig('CM-L%x-%s-all-normalized.svg' % (user_specified_layout_int, classifier), format='svg', bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train_x, train_y, test_x, test_y, classifier, target_classes):\n",
    "    if classifier == 'MLP':\n",
    "        pipe = Pipeline([\n",
    "            ('pre', ct), \n",
    "#                 ('feature_selection', SelectKBest(score_func=f_regression, k=4)), \n",
    "            ('clf', MLPClassifier(max_iter=5000))\n",
    "        ])\n",
    "    elif classifier == 'SVC':\n",
    "        pipe = Pipeline([\n",
    "            ('pre', ct), \n",
    "#                 ('feature_selection', SelectKBest(score_func=f_regression, k=4)), \n",
    "            ('clf', SVC(kernel='rbf', random_state=user_random_state))\n",
    "        ])\n",
    "\n",
    "    pipe.fit(train_x, train_y)\n",
    "    predicted_labels = pipe.predict(test_x)\n",
    "\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_subgroup(train_x, train_y, test_x, test_y, intermediate_labels, list_ids, subgroup_id, classifier, target_classes):\n",
    "    train_x_subgroup = train_x[np.isin(train_y, list_ids)]\n",
    "    train_y_subgroup = train_y[np.isin(train_y, list_ids)]\n",
    "    test_x_predicted_subgroup = test_x[np.isin(intermediate_labels, subgroup_id)]\n",
    "    test_y_corresponding_predicted_subgroup = test_y[np.isin(intermediate_labels, subgroup_id)]\n",
    "\n",
    "    predicted_labels_from_subgroup = []\n",
    "    if test_x_predicted_subgroup.size:\n",
    "        predicted_labels_from_subgroup = model(train_x_subgroup, train_y_subgroup, \n",
    "                                               test_x_predicted_subgroup, test_y_corresponding_predicted_subgroup, \n",
    "                                               classifier, target_classes)\n",
    "    else:\n",
    "        print(\"None of the participant's data was classified as subgroup {}\".format(subgroup_id))\n",
    "\n",
    "    return predicted_labels_from_subgroup, test_y_corresponding_predicted_subgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data_x, data_y, data_y_intermediate, classifier, target_classes):\n",
    "    group_k_fold = GroupKFold(n_splits=df[col_grp].nunique())\n",
    "\n",
    "    sample = np.array([])\n",
    "    predicted_targets = np.array([])\n",
    "    intermediate_actual_targets = np.array([])\n",
    "    actual_targets = np.array([])\n",
    "    predicted_targets_rights = np.array([])\n",
    "    actual_targets_rights = np.array([])\n",
    "    predicted_targets_lefts = np.array([])\n",
    "    actual_targets_lefts = np.array([])\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(group_k_fold.split(data_x, data_y, groups=groups)):\n",
    "        train_x, test_x = data_x[train_index], data_x[test_index]\n",
    "        train_y, test_y = data_y[train_index], data_y[test_index]\n",
    "        train_y_intermediate, test_y_intermediate = data_y_intermediate[train_index], data_y_intermediate[test_index]\n",
    "        print('fold %x (height: %.2f, weight: %.2f, bmi: %.2f)' % (i, test_x[0, cols_identifying_idx[0]], test_x[0, cols_identifying_idx[1]], test_x[0, cols_identifying_idx[2]]))\n",
    "\n",
    "        intermediate_output = model(train_x, train_y_intermediate, test_x, test_y_intermediate, classifier, target_classes)\n",
    "\n",
    "        predicted_targets = np.append(predicted_targets, intermediate_output)\n",
    "        intermediate_actual_targets = np.append(intermediate_actual_targets, test_y_intermediate)\n",
    "        actual_targets = np.append(actual_targets, test_y)\n",
    "\n",
    "#         cmd = ConfusionMatrixDisplay.from_predictions(test_y_intermediate, predicted_labels, \n",
    "#                                                       display_labels = target_classes, \n",
    "#                                                       xticks_rotation = 45, \n",
    "#                                                       normalize='true', \n",
    "#                                                       values_format = '.2f')\n",
    "#         plt.title('%s Confusion Matrix - Layout %x (height: %.2f, weight: %.2f, bmi: %.2f)' % (classifier, user_specified_layout_int, test_x[0, cols_identifying_idx[0]], test_x[0, cols_identifying_idx[1]], test_x[0, cols_identifying_idx[2]]))\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig('kfold confusion matrices/CM-L%x-%s-height-%.2f, weight-%.2f, bmi-%.2f.svg' % (user_specified_layout_int, classifier, test_x[0, cols_identifying_idx[0]], test_x[0, cols_identifying_idx[1]], test_x[0, cols_identifying_idx[2]]), format='svg', bbox_inches=\"tight\")\n",
    "#         plt.show()\n",
    "\n",
    "        output, corresponding_true_y = evaluate_subgroup(train_x, train_y, test_x, test_y, intermediate_output, [1,3,5], 100, classifier, target_classes)\n",
    "\n",
    "        predicted_targets_rights = np.append(predicted_targets_rights, output)\n",
    "        actual_targets_rights = np.append(actual_targets_rights, corresponding_true_y)\n",
    "\n",
    "        output, corresponding_true_y = evaluate_subgroup(train_x, train_y, test_x, test_y, intermediate_output, [2,4,6], 200, classifier, target_classes)\n",
    "\n",
    "        predicted_targets_lefts = np.append(predicted_targets_lefts, output)\n",
    "        actual_targets_lefts = np.append(actual_targets_lefts, corresponding_true_y)\n",
    "\n",
    "#         cmd = ConfusionMatrixDisplay.from_predictions(test_y_corresponding_predicted_rights, predicted_labels_2, \n",
    "#                                                       display_labels = ['Yearner Right', 'Log Right', 'Lost'], \n",
    "#                                                       xticks_rotation = 45, \n",
    "#                                                       normalize='true', \n",
    "#                                                       values_format = '.2f')\n",
    "#         plt.title('%s Confusion Matrix - Layout %x (height: %.2f, weight: %.2f, bmi: %.2f)' % (classifier, user_specified_layout_int, test_x[0, cols_identifying_idx[0]], test_x[0, cols_identifying_idx[1]], test_x[0, cols_identifying_idx[2]]))\n",
    "#         plt.tight_layout()\n",
    "# #         plt.savefig('kfold confusion matrices/CM-L%x-%s-height-%.2f, weight-%.2f, bmi-%.2f.svg' % (user_specified_layout_int, classifier, test_x[0, cols_identifying_idx[0]], test_x[0, cols_identifying_idx[1]], test_x[0, cols_identifying_idx[2]]), format='svg', bbox_inches=\"tight\")\n",
    "#         plt.show()\n",
    "\n",
    "    plot_confusion_matrix(intermediate_actual_targets, predicted_targets, classifier, target_classes)\n",
    "    plot_confusion_matrix(actual_targets_rights, predicted_targets_rights, classifier, list_positions)\n",
    "    plot_confusion_matrix(actual_targets_lefts, predicted_targets_lefts, classifier, list_positions)\n",
    "\n",
    "    new_predicted_targets = []\n",
    "    ctr_rights = 0\n",
    "    ctr_lefts = 0\n",
    "    for target in predicted_targets:\n",
    "        if target == 100:\n",
    "            new_predicted_targets.append(predicted_targets_rights[ctr_rights])\n",
    "            ctr_rights += 1\n",
    "        elif target == 200:\n",
    "            new_predicted_targets.append(predicted_targets_lefts[ctr_lefts])\n",
    "            ctr_lefts += 1\n",
    "        else:\n",
    "            new_predicted_targets.append(target)\n",
    "            \n",
    "#     np.putmask(predicted_targets, predicted_targets == 100, predicted_targets_rights)\n",
    "#     np.putmask(predicted_targets, predicted_targets == 200, predicted_targets_lefts)\n",
    "#     np.putmask(actual_targets, actual_targets == 100, actual_targets_rights)\n",
    "#     np.putmask(actual_targets, actual_targets == 200, actual_targets_lefts)\n",
    "\n",
    "    return actual_targets, new_predicted_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_inp.to_numpy()\n",
    "\n",
    "data = X\n",
    "target = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_targets, predicted_targets = evaluate_model(data, target, y_intermediate, 'SVC', list_grouped_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(actual_targets, predicted_targets, 'SVC', list_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_targets, predicted_targets = evaluate_model(data, target, y_intermediate, 'MLP', list_grouped_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(actual_targets, predicted_targets, 'MLP', list_positions)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
