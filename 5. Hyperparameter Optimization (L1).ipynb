{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDgRrdjhhFUB"
   },
   "source": [
    "## Step 1. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXTFbrVHhFUE"
   },
   "outputs": [],
   "source": [
    "# import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from joblib import dump, load\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, multilabel_confusion_matrix\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score, learning_curve, LearningCurveDisplay, train_test_split, validation_curve, ValidationCurveDisplay\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold, HalvingGridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, OneHotEncoder, RobustScaler, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# plotting learning curve\n",
    "# \"\"\"\n",
    "\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 6), sharey=True)\n",
    "\n",
    "# common_params = {\n",
    "#     \"X\": X,\n",
    "#     \"y\": y,\n",
    "#     \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "#     \"cv\": GroupKFold(n_splits=df[col_grp].nunique(), test_size=0.2, random_state=0),\n",
    "#     \"score_type\": \"both\",\n",
    "#     \"n_jobs\": 4,\n",
    "#     \"line_kw\": {\"marker\": \"o\"},\n",
    "#     \"std_display_style\": \"fill_between\",\n",
    "#     \"score_name\": \"Accuracy\",\n",
    "# }\n",
    "\n",
    "# for ax_idx, estimator in enumerate([naive_bayes, svc]):\n",
    "#     LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax[ax_idx])\n",
    "#     handles, label = ax[ax_idx].get_legend_handles_labels()\n",
    "#     ax[ax_idx].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
    "#     ax[ax_idx].set_title(f\"Learning Curve for {estimator.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mPPkojMhFUF"
   },
   "source": [
    "## Step 2a. Declare user variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T3-fnNiUhFUG"
   },
   "outputs": [],
   "source": [
    "is_test = False\n",
    "\n",
    "user_specified_ntbk_identifier = 'failure analysis' #to uniquely identify the results generated by this notebook\n",
    "user_specified_output_folder = 'Failure Analysis/'\n",
    "\n",
    "user_specified_layout = 'layout1'\n",
    "user_specified_layout_int = int(user_specified_layout[len(user_specified_layout) - 1])\n",
    "user_specified_nth = 3\n",
    "\n",
    "user_test_size = 0.2\n",
    "user_random_state = 1\n",
    "\n",
    "if user_specified_layout_int == 1:\n",
    "    ith_inp_col = 16\n",
    "else:\n",
    "    ith_inp_col = 20\n",
    "\n",
    "n_steps = 2\n",
    "list_filenames = {\n",
    "    'layout1':'dataset_1.csv',\n",
    "    'layout2':'dataset_2.csv',\n",
    "}\n",
    "list_columns = {\n",
    "    'layout1_all':['timestamp','posture_id','posture_label','s01','s02','s03','s04','s05','s06','s07','s08','s09','s10','s11','s12','s13','s14','s15','s16','birth_year','sex','height','weight','bmi','bmi_label','full_name','nth','round'],\n",
    "    'layout2_all':['timestamp','posture_id','posture_label','s01','s02','s03','s04','s05','s06','s07','s08','s09','s10','s11','s12','s13','s14','s15','s16','s17','s18','s19','s20','birth_year','sex','height','weight','bmi','bmi_label','full_name','nth','round'],\n",
    "    'layout1_cat_inp':[],\n",
    "    'layout1_num_inp':['s01','s02','s03','s04','s05','s06','s07','s08','s09','s10','s11','s12','s13','s14','s15','s16', 'height','weight','bmi'],\n",
    "    'layout2_cat_inp':[],\n",
    "    'layout2_num_inp':['s01','s02','s03','s04','s05','s06','s07','s08','s09','s10','s11','s12','s13','s14','s15','s16','s17','s18','s19','s20', 'height','weight','bmi'],\n",
    "}\n",
    "list_positions = ['Yearner_Right', 'Yearner_Left', 'Fetal_Right', 'Fetal_Left', 'Log_Right', 'Log_Left', 'Supine', 'Prone', # 'Empty'\n",
    "]\n",
    "dict_positions = {\n",
    "    1   : 'Yearner_Right',\n",
    "    2   : 'Yearner_Left',\n",
    "    3   : 'Fetal_Right',\n",
    "    4   : 'Fetal_Left',\n",
    "    5   : 'Log_Right',\n",
    "    6   : 'Log_Left',\n",
    "    7   : 'Supine',\n",
    "    8   : 'Prone',\n",
    "    100 : 'YRLR',\n",
    "    200 : 'YLLL',\n",
    "}\n",
    "list_grouped_positions = [\n",
    "    'Fetal_Right',\n",
    "    'Fetal_Left',\n",
    "    'Supine',\n",
    "    'Prone',\n",
    "    'YRLR',\n",
    "    'YLLL',\n",
    "]\n",
    "\n",
    "participants = {\n",
    "    22.89 : 'Karen_Alli',\n",
    "    23.73 : 'Jenalene_Ambat',\n",
    "    25.34 : 'Rodrigo_Baldos',\n",
    "    34.34 : 'Karlo_Barba',\n",
    "    27.4  : 'Harold_Paulo_Bautista',\n",
    "    29.41 : 'Gerwin_Rommel_Caballes',\n",
    "    23.78 : 'Randy_Caldo',\n",
    "    27.68 : 'Joey_Callos',\n",
    "    23.83 : 'Delford_Gamayo',\n",
    "    35.2  : 'Criselda_Garcia',\n",
    "    24.31 : 'Hans_Oswald_Ibrahim',\n",
    "    33.02 : 'Marven_Ignacio',\n",
    "    19.35 : 'Zarah_Jane_Jolejole',\n",
    "    26.24 : 'Karl_Michael_Leyson',\n",
    "    24.91 : 'Ryan_Dominic_Lin',\n",
    "    24.58 : 'Joanna_May_Lisondra',\n",
    "    20.2  : 'Jose_Ignacio_Locsin',\n",
    "    25.12 : 'Christopher_Madrona',\n",
    "    27.02 : 'Karl_Justin_Ngu',\n",
    "    25.01 : 'Gabriel_Joseph_Pua',\n",
    "    24.61 : 'Catalina_Quiogue',\n",
    "    24.22 : 'Michelle_Ramos',\n",
    "    34.56 : 'Oliver_Reyes',\n",
    "    25.4  : 'Emily_Robrigado',\n",
    "    19.39 : 'Lloyd_Saavedra',\n",
    "    42.52 : 'Mark_Gavin_Sanchez',\n",
    "    20.34 : 'Flory-Anne_Sinco',\n",
    "    23.53 : 'Adrian_Aerol_Supranes',\n",
    "    28.62 : 'Vince_Allen_Sy',\n",
    "    20.31 : 'Richard_Tabano',\n",
    "    33.31 : 'Rommel_Tupig',\n",
    "    25.31 : 'Philip_Uy',\n",
    "    25.56 : 'Jayson_Valenzuela',\n",
    "    22.06 : 'Aris_Jastin_Venan',\n",
    "    23.56 : 'Angelica_Villanueva',\n",
    "    22.46 : 'Jared_Sy',\n",
    "    26.83 : 'Nyles_Chan',\n",
    "    29.76 : 'Paul_Delariarte',\n",
    "}\n",
    "\n",
    "filename = list_filenames[user_specified_layout]\n",
    "cols_all = list_columns[user_specified_layout + '_all']\n",
    "cols_cat_inp = list_columns[user_specified_layout + '_cat_inp']\n",
    "cols_num_inp = list_columns[user_specified_layout + '_num_inp']\n",
    "cols_inp = cols_cat_inp + cols_num_inp\n",
    "cols_non_inp = list(set(cols_all) - set(cols_inp))\n",
    "\n",
    "cols_num_inp_std = ['height','weight','bmi']\n",
    "cols_num_inp_nrm = list(set(cols_num_inp) - set(cols_num_inp_std))\n",
    "\n",
    "col_grp = 'full_name'\n",
    "col_trg = 'posture_id'\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '{:.2f}'.format(x))\n",
    "sns.reset_orig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIpQ_xVEhFUH"
   },
   "source": [
    "## Step 2b. Declare and prepare needed variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename, usecols = cols_all)\n",
    "\n",
    "df = df[df.nth <= 5]\n",
    "\n",
    "if(isinstance(user_specified_nth, int)):\n",
    "    print('user_specified_nth is an instance of int')\n",
    "    df = df[df.nth == user_specified_nth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "n2Tq6jamhFUI",
    "outputId": "03ff5da5-6b56-4553-b782-7b0d8d54a977"
   },
   "outputs": [],
   "source": [
    "def categorize(row):\n",
    "    if row['posture_label'] == 'Yearner_Right' or row['posture_label'] == 'Log_Right':\n",
    "        return 100\n",
    "    elif row['posture_label'] == 'Yearner_Left' or row['posture_label'] == 'Log_Left':\n",
    "        return 200\n",
    "    else:\n",
    "        return row['posture_id']\n",
    "\n",
    "df_inp = df[cols_inp]\n",
    "\n",
    "X = df_inp\n",
    "\n",
    "y = df[col_trg].values\n",
    "y_intermediate = df.apply(lambda row: categorize(row), axis=1).values\n",
    "groups = df[col_grp].values\n",
    "\n",
    "# TODO: delete cols_identifying_idx and other calls to this variable\n",
    "cols_identifying_idx = df_inp.columns.get_indexer(['height','weight','bmi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cat_inp_idx = df_inp.columns.get_indexer(cols_cat_inp)\n",
    "cols_num_inp_idx = df_inp.columns.get_indexer(cols_num_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_cat_inp = [\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "]\n",
    "pipe_cat_inp = Pipeline(steps_cat_inp)\n",
    "\n",
    "steps_num_inp = [\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "]\n",
    "pipe_num_inp = Pipeline(steps_num_inp)\n",
    "\n",
    "ct = ColumnTransformer(transformers=[\n",
    "          ('categorical', pipe_cat_inp, cols_cat_inp_idx),\n",
    "          ('numerical', pipe_num_inp, cols_num_inp_idx)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBFxrSSahFUM"
   },
   "source": [
    "## Step 2c. Declare needed functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_incorrect_predictions(actual_targets, predicted_targets, classifier):\n",
    "    cols_display = ['timestamp','height','weight','bmi','bmi_label','full_name','nth','round','posture_id','posture_label','actl','pred', 'pred_label']\n",
    "\n",
    "    df_display = df\n",
    "    df_display['actl'] = actual_targets\n",
    "    df_display['pred'] = predicted_targets\n",
    "    df_display['pred_label'] = predicted_targets\n",
    "\n",
    "    df_incorrect = df_display[cols_display][actual_targets != predicted_targets]\n",
    "    df_incorrect = df_incorrect.replace({'pred_label': dict_positions})\n",
    "    df_incorrect.to_csv(\"incorrect_L{}_{}.csv\".format(user_specified_layout_int, classifier), index=False, encoding='utf-8-sig')\n",
    "    display(df_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(actual_targets, predicted_targets, target_classes, result_identifier):\n",
    "    print(result_identifier)\n",
    "    print(accuracy_score(actual_targets, predicted_targets))\n",
    "    # print(precision_score(actual_targets, predicted_targets, average='micro'))\n",
    "    # print(recall_score(actual_targets, predicted_targets, average='micro'))\n",
    "    # print(f1_score(actual_targets, predicted_targets_intermediate, average='micro'))\n",
    "    # try:\n",
    "    #     print(classification_report(actual_targets, predicted_targets, target_names=target_classes))\n",
    "    # except:\n",
    "    #     print(classification_report(actual_targets, predicted_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_confusion_matrix(actual_targets, predicted_targets, normalize=None, title='Confusion Matrix'):\n",
    "    adjusted_target_classes = [dict_positions[x] for x in sorted(set(actual_targets).union(predicted_targets))]\n",
    "    # adjusted_target_classes = []\n",
    "    # for i, val in enumerate(sorted(set(actual_targets).union(predicted_targets))):\n",
    "    #     adjusted_target_classes.append(dict_positions[val])\n",
    "\n",
    "    \"\"\"this if condition was put in place for failure analysis\"\"\"\n",
    "    if not (actual_targets == predicted_targets).all():\n",
    "        if normalize is None:\n",
    "            # print(\"Confusion Matrix, Without Normalized Counts\")\n",
    "            ConfusionMatrixDisplay.from_predictions(actual_targets, predicted_targets, \n",
    "                                                    display_labels = adjusted_target_classes, \n",
    "                                                    xticks_rotation = 45)\n",
    "        else:\n",
    "            cnf_matrix = confusion_matrix(actual_targets, predicted_targets)\n",
    "            cnf_matrix = cnf_matrix.astype('float') / cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "            # print(\"Confusion Matrix, With Normalized Counts\")\n",
    "            ConfusionMatrixDisplay.from_predictions(actual_targets, predicted_targets, \n",
    "                                                    display_labels = adjusted_target_classes, \n",
    "                                                    xticks_rotation = 45, \n",
    "                                                    normalize=normalize, \n",
    "                                                    values_format = '.2f')\n",
    "\n",
    "        plt.title(title)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrices(actual_targets, predicted_targets, classifier, target_classes, result_identifier):\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    print_metrics(actual_targets, predicted_targets, target_classes, result_identifier)\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    plt.figure()\n",
    "    generate_confusion_matrix(actual_targets, predicted_targets, title='{} Confusion Matrix - Layout {} ({}, Without Normalized Counts)'.format(classifier, user_specified_layout_int, result_identifier))\n",
    "    plt.savefig('{}CM-{}S-L{}-{}-nonnormalized ({} {} results).png'.format(user_specified_output_folder, n_steps, user_specified_layout_int, classifier, result_identifier, user_specified_ntbk_identifier), format='png', bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot normalized confusion matrix\n",
    "    plt.figure()\n",
    "    generate_confusion_matrix(actual_targets, predicted_targets, normalize='true', title='{} Confusion Matrix - Layout {} ({}, With Normalized Counts)'.format(classifier, user_specified_layout_int, result_identifier))\n",
    "    plt.savefig('{}CM-{}S-L{}-{}-normalized ({} {} results).png'.format(user_specified_output_folder, n_steps, user_specified_layout_int, classifier, result_identifier, user_specified_ntbk_identifier), format='png', bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pipeline(classifier):\n",
    "    if classifier == 'MLP':\n",
    "        pipe = Pipeline([\n",
    "            ('pre', ct), \n",
    "            ('clf', MLPClassifier(random_state=user_random_state))\n",
    "        ])\n",
    "    elif classifier == 'SVM':\n",
    "        pipe = Pipeline([\n",
    "            ('pre', ct), \n",
    "            ('clf', SVC(random_state=user_random_state))\n",
    "        ])\n",
    "\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_final_models(data_x, data_y, data_y_intermediate, classifier):\n",
    "    pipe_intermediate = generate_pipeline(classifier)\n",
    "    pipe_intermediate.fit(data_x, data_y_intermediate)\n",
    "    dump(pipe_intermediate, 'L{}-YearnerLog-Step1.joblib'.format(user_specified_layout_int))\n",
    "\n",
    "    pipe_rights = generate_pipeline(classifier)\n",
    "    pipe_rights.fit(data_x[np.isin(data_y, [1,5])], data_y[np.isin(data_y, [1,5])])\n",
    "    dump(pipe_rights, 'L{}-YearnerLog-Step2rights.joblib'.format(user_specified_layout_int))\n",
    "\n",
    "    pipe_lefts = generate_pipeline(classifier)\n",
    "    pipe_lefts.fit(data_x[np.isin(data_y, [2,6])], data_y[np.isin(data_y, [2,6])])\n",
    "    dump(pipe_lefts, 'L{}-YearnerLog-Step2lefts.joblib'.format(user_specified_layout_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train_x, train_y, test_x, test_y, classifier):\n",
    "    pipe = generate_pipeline(classifier)\n",
    "\n",
    "    pipe.fit(train_x, train_y)\n",
    "    predicted_targets = pipe.predict(test_x)\n",
    "\n",
    "    return predicted_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_subgroup(train_x, train_y, test_x, test_y, intermediate_predicted, list_subgroup_posture_ids, subgroup_id, classifier):\n",
    "    train_x_subgroup = train_x[np.isin(train_y, list_subgroup_posture_ids)]\n",
    "    train_y_subgroup = train_y[np.isin(train_y, list_subgroup_posture_ids)]\n",
    "    test_x_predicted_subgroup = test_x[np.isin(intermediate_predicted, subgroup_id)]\n",
    "    test_y_corresponding_predicted_subgroup = test_y[np.isin(intermediate_predicted, subgroup_id)]\n",
    "\n",
    "    predicted_targets_from_subgroup = []\n",
    "    if test_x_predicted_subgroup.size:\n",
    "        predicted_targets_from_subgroup = model(train_x_subgroup, train_y_subgroup, \n",
    "                                               test_x_predicted_subgroup, test_y_corresponding_predicted_subgroup, \n",
    "                                               classifier)\n",
    "    else:\n",
    "        print(\"None of the participant's data was classified as subgroup {}\".format(subgroup_id))\n",
    "\n",
    "    return test_y_corresponding_predicted_subgroup, predicted_targets_from_subgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_accuracy_scores(list_actual_targets, list_predicted_targets, info_h, info_w, info_b, classifier):\n",
    "    cols_scores = ['height','weight','bmi','bmi_label','full_name','intermediate','rights','lefts','overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data_x, data_y, data_y_intermediate, classifier):\n",
    "    group_k_fold = GroupKFold(n_splits=df[col_grp].nunique())\n",
    "\n",
    "    actual_targets = np.array([])\n",
    "    actual_targets_intermediate = np.array([])\n",
    "    predicted_targets_intermediate = np.array([])\n",
    "    actual_targets_rights = np.array([])\n",
    "    predicted_targets_rights = np.array([])\n",
    "    actual_targets_lefts = np.array([])\n",
    "    predicted_targets_lefts = np.array([])\n",
    "\n",
    "    \"\"\"\n",
    "    simulate k number of folds\n",
    "    \"\"\"\n",
    "    for i, (train_index, test_index) in enumerate(group_k_fold.split(data_x, data_y, groups=groups)):\n",
    "        train_x, test_x = data_x[train_index], data_x[test_index]\n",
    "        train_y, test_y = data_y[train_index], data_y[test_index]\n",
    "        train_y_intermediate, test_y_intermediate = data_y_intermediate[train_index], data_y_intermediate[test_index]\n",
    "        actual_targets = np.append(actual_targets, test_y)\n",
    "\n",
    "        info_h = np.unique(test_x[..., cols_identifying_idx[0]])\n",
    "        info_w = np.unique(test_x[..., cols_identifying_idx[1]])\n",
    "        info_b = np.unique(test_x[..., cols_identifying_idx[2]])\n",
    "\n",
    "        print('fold {} (height: {:.2f}, weight: {:.2f}, bmi: {:.2f})'.format(i, info_h[0], info_w[0], info_b[0]))\n",
    "\n",
    "        \"\"\"\n",
    "        intermediate model, group test data into: FR, FL, S, P + YRLR, YLLL\n",
    "        \"\"\"\n",
    "\n",
    "        fold_predicted_targets_intermediate = model(train_x, train_y_intermediate, test_x, test_y_intermediate, classifier)\n",
    "\n",
    "        actual_targets_intermediate = np.append(actual_targets_intermediate, test_y_intermediate)\n",
    "        predicted_targets_intermediate = np.append(predicted_targets_intermediate, fold_predicted_targets_intermediate)\n",
    "\n",
    "        print_metrics(test_y_intermediate, fold_predicted_targets_intermediate, target_classes=list_positions, result_identifier='intermediate')\n",
    "        \"\"\"for failure analysis: generate confusion matrix for participants whose data arent perfectly classified by the intermediate model\"\"\"\n",
    "        plt.figure()\n",
    "        generate_confusion_matrix(test_y_intermediate, fold_predicted_targets_intermediate, normalize='true', title='{} Confusion Matrix (Intermediate) - Layout {} (height: {:.2f}, weight: {:.2f}, bmi: {:.2f})'.format(classifier, user_specified_layout_int, info_h[0], info_w[0], info_b[0]))\n",
    "        # plt.savefig('{}kfold confusion matrices/CM-{}S-L{}-{}-intermediate-height-{:.2f}, weight-{:.2f}, bmi-{:.2f}.png'.format(user_specified_output_folder, n_steps, user_specified_layout_int, classifier, info_h[0], info_w[0], info_b[0]), format='png', bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "\n",
    "        \"\"\"\n",
    "        YRLR subgroup model, sift predicted YRLR from intermediate model into: YR and LR\n",
    "        \"\"\"\n",
    "\n",
    "        subgroup_actual_targets, subgroup_predicted_targets = evaluate_subgroup(train_x, train_y, test_x, test_y, fold_predicted_targets_intermediate, [1,5], 100, classifier)\n",
    "\n",
    "        print_metrics(subgroup_actual_targets, subgroup_predicted_targets, target_classes=list_positions, result_identifier='right_subgroup')\n",
    "        # plt.figure()\n",
    "        # generate_confusion_matrix(subgroup_actual_targets, subgroup_predicted_targets, normalize='true', title='{} Confusion Matrix (Right Subgroup) - Layout {} (height: {:.2f}, weight: {:.2f}, bmi: {:.2f})'.format(classifier, user_specified_layout_int, info_h[0], info_w[0], info_b[0]))\n",
    "        # # plt.savefig('{}kfold confusion matrices/CM-{}S-L{}-{}-right-subgroup-height-{:.2f}, weight-{:.2f}, bmi-{:.2f}.png'.format(user_specified_output_folder, n_steps, user_specified_layout_int, classifier, info_h[0], info_w[0], info_b[0]), format='png', bbox_inches=\"tight\")\n",
    "        # plt.show()\n",
    "\n",
    "        actual_targets_rights = np.append(actual_targets_rights, subgroup_actual_targets)\n",
    "        predicted_targets_rights = np.append(predicted_targets_rights, subgroup_predicted_targets)\n",
    "\n",
    "        \"\"\"\n",
    "        YLLL subgroup model, sift predicted YLLL from intermediate model into: YL and LL\n",
    "        \"\"\"\n",
    "\n",
    "        subgroup_actual_targets, subgroup_predicted_targets = evaluate_subgroup(train_x, train_y, test_x, test_y, fold_predicted_targets_intermediate, [2,6], 200, classifier)\n",
    "\n",
    "        print_metrics(subgroup_actual_targets, subgroup_predicted_targets, target_classes=list_positions, result_identifier='left_subgroup')\n",
    "        # plt.figure()\n",
    "        # generate_confusion_matrix(subgroup_actual_targets, subgroup_predicted_targets, normalize='true', title='{} Confusion Matrix (Left Subgroup) - Layout {} (height: {:.2f}, weight: {:.2f}, bmi: {:.2f})'.format(classifier, user_specified_layout_int, info_h[0], info_w[0], info_b[0]))\n",
    "        # # plt.savefig('{}kfold confusion matrices/CM-{}S-L{}-{}-left-subgroup-height-{:.2f}, weight-{:.2f}, bmi-{:.2f}.png'.format(user_specified_output_folder, n_steps, user_specified_layout_int, classifier, info_h[0], info_w[0], info_b[0]), format='png', bbox_inches=\"tight\")\n",
    "        # plt.show()\n",
    "\n",
    "        actual_targets_lefts = np.append(actual_targets_lefts, subgroup_actual_targets)\n",
    "        predicted_targets_lefts = np.append(predicted_targets_lefts, subgroup_predicted_targets)\n",
    "        \n",
    "        # save_accuracy_scores(list_actual_targets, list_predicted_targets, info_h, info_w, info_b, classifier)\n",
    "\n",
    "    plot_confusion_matrices(actual_targets_intermediate, predicted_targets_intermediate, classifier, list_grouped_positions, 'overall_intermediate')\n",
    "    plot_confusion_matrices(actual_targets_rights, predicted_targets_rights, classifier, list_positions, 'overall_right_subgroup')\n",
    "    plot_confusion_matrices(actual_targets_lefts, predicted_targets_lefts, classifier, list_positions, 'overall_left_subgroup')\n",
    "\n",
    "    translated_predicted_targets = []\n",
    "    ctr_rights = 0\n",
    "    ctr_lefts = 0\n",
    "    for target in predicted_targets_intermediate:\n",
    "        if target == 100:\n",
    "            translated_predicted_targets.append(predicted_targets_rights[ctr_rights])\n",
    "            ctr_rights += 1\n",
    "        elif target == 200:\n",
    "            translated_predicted_targets.append(predicted_targets_lefts[ctr_lefts])\n",
    "            ctr_lefts += 1\n",
    "        else:\n",
    "            translated_predicted_targets.append(target)\n",
    "\n",
    "    return actual_targets, translated_predicted_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_inp.to_numpy()\n",
    "\n",
    "data = X\n",
    "target = y\n",
    "\n",
    "gkf = GroupKFold(n_splits=df[col_grp].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_optimization(classifier):\n",
    "    if classifier == 'MLP':\n",
    "        param_grid = [\n",
    "            {\n",
    "                'clf__hidden_layer_sizes': [\n",
    "                    (10,30,10),\n",
    "                    (50,50,50), (50,100,50), (100,), (50,),\n",
    "                    (1,),(2,),(3,),(4,),(5,),(6,),(7,),(8,),(9,),(10,),(11,), (12,),(13,),(14,),(15,),(16,),(17,),(18,),(19,),(20,),(21,)\n",
    "                    ],\n",
    "                'clf__activation': ['tanh', 'relu'], # ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                'clf__solver': ['sgd', 'adam'], # ['lbfgs', 'sgd', 'adam'],\n",
    "                'clf__alpha': [0.0001, 0.05],\n",
    "                'clf__learning_rate': ['constant', 'adaptive'],\n",
    "                # 'clf__learning_rate_init': np.arange(0.01, 1),\n",
    "                'clf__max_iter': [100000],\n",
    "                # 'clf__early_stoppping': [True],\n",
    "            }\n",
    "        ]\n",
    "    elif classifier == 'SVM':\n",
    "        param_grid = [\n",
    "            {\n",
    "                'clf__C': [0.1, 1, 10, 100], # 0.1 < c < 100; [0.1, 1, 10, 100, 1000]\n",
    "                'clf__gamma': [0.0001, 0.001, 0.01, 0.1, 1, 'scale', 'auto'], # 0.0001 < gamma < 10\n",
    "                'clf__kernel': ['rbf', 'poly'],\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    gs = GridSearchCV(generate_pipeline(classifier), param_grid, cv=gkf.split(X, y, groups=groups)).fit(X, y)\n",
    "    \n",
    "    # gs = HalvingGridSearchCV(generate_pipeline(classifier), param_grid, \n",
    "    #                         #  scoring=['accuracy'],\n",
    "    #                          n_jobs=-1, \n",
    "    #                         # #  refit='acccuracy'???,\n",
    "    #                          cv=gkf.split(X, y, groups=groups)).fit(X, y)\n",
    "\n",
    "    # gs = RandomizedSearchCV(generate_pipeline(classifier), param_grid, n_jobs=-1, cv=gkf.split(X, y, groups=groups)).fit(X, y)\n",
    "\n",
    "    print('The best accuracy score for the training dataset is {:.4f}'.format(gs.best_score_))\n",
    "    print('The best hyperparameters are {}'.format(gs.best_params_))\n",
    "    # print('The accuracy score for the testing dataset is {.4f}'.format(grid_search.score(X_test_transformed, y_test)))\n",
    "\n",
    "    return gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_gs = hyperparameter_optimization('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(svm_gs, X, y)\n",
    "display = LearningCurveDisplay(train_sizes=train_sizes, train_scores=train_scores, test_scores=test_scores, score_name=\"Score\")\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_gs = hyperparameter_optimization('MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(mlp_gs, X, y)\n",
    "display = LearningCurveDisplay(train_sizes=train_sizes, train_scores=train_scores, test_scores=test_scores, score_name=\"Score\")\n",
    "display.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
